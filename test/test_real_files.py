#!/usr/bin/env python3
"""
æµ‹è¯•å®é™…æ–‡ä»¶çš„å†…å®¹æå–åŠŸèƒ½
"""

from utils.logger import logger
from database.models import DatabaseManager
from api.upload import extract_file_content, validate_file_type
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))


try:
    from docx import Document
    docx_available = True
except ImportError:
    docx_available = False

try:
    import PyPDF2
    pdf_available = True
except ImportError:
    pdf_available = False


async def create_test_files():
    """åˆ›å»ºå„ç§æ ¼å¼çš„æµ‹è¯•æ–‡ä»¶"""
    test_dir = Path("test/temp_real_files")
    test_dir.mkdir(exist_ok=True)

    # 1. åˆ›å»ºMarkdownæ–‡ä»¶
    md_file = test_dir / "sample.md"
    md_content = """# RAGç³»ç»Ÿæ–‡æ¡£

## ç®€ä»‹
è¿™æ˜¯ä¸€ä¸ªæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿï¼Œç”¨äºå¤„ç†æ–‡æ¡£å‘é‡åŒ–å’Œæ™ºèƒ½é—®ç­”ã€‚

## ä¸»è¦åŠŸèƒ½
1. **æ–‡æ¡£ä¸Šä¼ **: æ”¯æŒPDFã€DOCXã€Markdownæ ¼å¼
2. **å‘é‡åŒ–å¤„ç†**: ä½¿ç”¨OpenAI APIè¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
3. **æ™ºèƒ½æ£€ç´¢**: åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ–‡æ¡£æ£€ç´¢
4. **ä»»åŠ¡ç®¡ç†**: å¼‚æ­¥å¤„ç†å‘é‡åŒ–ä»»åŠ¡é˜Ÿåˆ—

## æŠ€æœ¯æ¶æ„
- **åç«¯**: FastAPI + SQLite + aiosqlite
- **å‘é‡åŒ–**: OpenAI Embeddings API
- **æ–‡æ¡£å¤„ç†**: python-docx, PyPDF2
- **ä»»åŠ¡é˜Ÿåˆ—**: asyncio + çº¿ç¨‹æ± 

## ä½¿ç”¨æ–¹æ³•
```python
# ä¸Šä¼ æ–‡ä»¶
POST /api/v1/files

# æŸ¥çœ‹æ–‡ä»¶å†…å®¹
GET /api/v1/files/{file_id}

# åˆ é™¤æ–‡ä»¶
DELETE /api/v1/files/{file_id}
```

> æ³¨æ„: ç³»ç»Ÿæ”¯æŒä¸­æ–‡æ–‡æ¡£å¤„ç†
"""

    md_file.write_text(md_content, encoding='utf-8')
    logger.info(f"âœ… åˆ›å»ºMarkdownæ–‡ä»¶: {md_file}")

    # 2. åˆ›å»ºDOCXæ–‡ä»¶
    if docx_available:
        docx_file = test_dir / "sample.docx"
        doc = Document()

        # æ·»åŠ æ ‡é¢˜
        doc.add_heading('RAGç³»ç»Ÿç”¨æˆ·æ‰‹å†Œ', 0)

        # æ·»åŠ æ®µè½
        doc.add_heading('ç³»ç»Ÿæ¦‚è¿°', level=1)
        doc.add_paragraph(
            'RAG (Retrieval-Augmented Generation) ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºFastAPIå¼€å‘çš„æ–‡æ¡£å¤„ç†å’Œå‘é‡åŒ–å¹³å°ã€‚')

        doc.add_heading('ä¸»è¦ç‰¹æ€§', level=1)
        features = doc.add_paragraph()
        features.add_run('â€¢ æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼\n')
        features.add_run('â€¢ å¼‚æ­¥å‘é‡åŒ–å¤„ç†\n')
        features.add_run('â€¢ æ™ºèƒ½æ–‡æ¡£æ£€ç´¢\n')
        features.add_run('â€¢ å®Œæ•´çš„APIæ¥å£')

        doc.add_heading('å®‰è£…é…ç½®', level=1)
        doc.add_paragraph('ä½¿ç”¨Poetryè¿›è¡Œä¾èµ–ç®¡ç†ï¼š')
        doc.add_paragraph('poetry install', style='Intense Quote')

        doc.add_heading('APIä½¿ç”¨', level=1)
        doc.add_paragraph(
            'ç³»ç»Ÿæä¾›RESTful APIæ¥å£ï¼Œæ”¯æŒæ–‡ä»¶ä¸Šä¼ ã€å†…å®¹æŸ¥çœ‹å’Œåˆ é™¤æ“ä½œã€‚æ‰€æœ‰æ¥å£éƒ½è¿”å›ç»Ÿä¸€çš„JSONå“åº”æ ¼å¼ã€‚')

        doc.save(docx_file)
        logger.info(f"âœ… åˆ›å»ºDOCXæ–‡ä»¶: {docx_file}")

    return test_dir


async def test_real_file_extraction():
    """æµ‹è¯•çœŸå®æ–‡ä»¶çš„å†…å®¹æå–"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•çœŸå®æ–‡ä»¶å†…å®¹æå–...")

    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_dir = await create_test_files()

    try:
        # æµ‹è¯•æ‰€æœ‰æ–‡ä»¶
        test_files = list(test_dir.glob("*"))

        for file_path in test_files:
            if file_path.is_file():
                file_ext = file_path.suffix.lower()
                logger.info(f"\nğŸ“„ æµ‹è¯•æ–‡ä»¶: {file_path.name} ({file_ext})")

                # éªŒè¯æ–‡ä»¶ç±»å‹
                with open(file_path, 'rb') as f:
                    file_content = f.read()

                if validate_file_type(file_path.name, file_content):
                    logger.info("âœ… æ–‡ä»¶ç±»å‹éªŒè¯é€šè¿‡")

                    # æå–å†…å®¹
                    extracted_content = await extract_file_content(file_path, file_ext)

                    if extracted_content and "æå–æ–‡ä»¶å†…å®¹å¤±è´¥" not in extracted_content:
                        logger.info("âœ… å†…å®¹æå–æˆåŠŸ")
                        logger.info(f"ğŸ“ å†…å®¹é•¿åº¦: {len(extracted_content)} å­—ç¬¦")

                        # æ˜¾ç¤ºå‰200å­—ç¬¦
                        preview = extracted_content[:200].replace('\n', ' ')
                        logger.info(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {preview}...")

                        # æ£€æŸ¥å…³é”®è¯
                        keywords = ["RAG", "ç³»ç»Ÿ", "å‘é‡åŒ–", "API", "æ–‡æ¡£"]
                        found_keywords = [
                            kw for kw in keywords if kw in extracted_content]
                        logger.info(f"ğŸ” æ‰¾åˆ°å…³é”®è¯: {found_keywords}")

                    else:
                        logger.error(f"âŒ å†…å®¹æå–å¤±è´¥: {extracted_content}")
                else:
                    logger.error("âŒ æ–‡ä»¶ç±»å‹éªŒè¯å¤±è´¥")

        # æµ‹è¯•æ•°æ®åº“é›†æˆ
        logger.info(f"\nğŸ—„ï¸ æµ‹è¯•æ•°æ®åº“é›†æˆ...")

        db_manager = DatabaseManager()
        await db_manager.init_database()

        # æ¨¡æ‹Ÿæ–‡ä»¶ä¸Šä¼ åˆ°æ•°æ®åº“
        md_file = test_dir / "sample.md"
        if md_file.exists():
            await db_manager.insert_file(
                file_id="test_md_content",
                original_name="sample.md",
                file_name="sample.md",
                file_path=str(md_file),
                file_type=".md",
                file_size=md_file.stat().st_size
            )

            logger.info(f"âœ… æ–‡ä»¶è®°å½•åˆ›å»ºæˆåŠŸ: test_md_content")

            # é€šè¿‡APIè·å–æ–‡ä»¶å†…å®¹
            file_info = await db_manager.get_file_by_id("test_md_content")
            if file_info:
                content = await extract_file_content(Path(file_info["file_path"]), file_info["file_type"])
                if content and len(content) > 100:
                    logger.info("âœ… æ•°æ®åº“é›†æˆæµ‹è¯•æˆåŠŸ")
                else:
                    logger.error("âŒ æ•°æ®åº“é›†æˆæµ‹è¯•å¤±è´¥")

            # æ¸…ç†æµ‹è¯•è®°å½•
            await db_manager.delete_file_and_documents("test_md_content")
            logger.info("ğŸ—‘ï¸ æ¸…ç†æµ‹è¯•è®°å½•")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        import shutil
        if test_dir.exists():
            shutil.rmtree(test_dir)
            logger.info("ğŸ—‘ï¸ æ¸…ç†æµ‹è¯•æ–‡ä»¶")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await test_real_file_extraction()
        logger.info("âœ… çœŸå®æ–‡ä»¶å†…å®¹æå–æµ‹è¯•å®Œæˆ")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
