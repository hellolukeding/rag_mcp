#!/usr/bin/env python3
"""
å‘é‡åŒ–æœåŠ¡æ¨¡æ‹Ÿæµ‹è¯•è„šæœ¬
ä½¿ç”¨æ¨¡æ‹Ÿçš„å‘é‡åŒ–APIæµ‹è¯•åŠŸèƒ½
"""

import asyncio
import os
import sys
import time
import uuid
from pathlib import Path
from unittest.mock import AsyncMock, patch

from dotenv import load_dotenv

from core.vectorize import TaskFile, Vectorize
from database.models import db_manager
from utils.logger import logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))


class MockVectorizeService(Vectorize):
    """æ¨¡æ‹Ÿå‘é‡åŒ–æœåŠ¡ï¼Œä¸è°ƒç”¨çœŸå®API"""

    def __init__(self, max_workers: int = 2):
        super().__init__(max_workers)
        # é‡å†™å‘é‡åŒ–å®¢æˆ·ç«¯çš„æ–¹æ³•
        self.queue._get_embeddings_batch = self._mock_get_embeddings_batch

    async def _mock_get_embeddings_batch(self, texts):
        """æ¨¡æ‹Ÿè·å–å‘é‡åŒ–ç»“æœ"""
        # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await asyncio.sleep(0.5)

        # è¿”å›æ¨¡æ‹Ÿçš„å‘é‡æ•°æ® (768ç»´å‘é‡)
        mock_embeddings = []
        for text in texts:
            # ç”ŸæˆåŸºäºæ–‡æœ¬é•¿åº¦çš„æ¨¡æ‹Ÿå‘é‡
            embedding = [0.1 * (i % 10) for i in range(768)]
            mock_embeddings.append(embedding)

        logger.info(f"æ¨¡æ‹Ÿå‘é‡åŒ–å®Œæˆï¼Œå¤„ç†äº† {len(texts)} ä¸ªæ–‡æœ¬å—")
        return mock_embeddings


async def setup():
    """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
    logger.info("=" * 80)
    logger.info("å¼€å§‹æ¨¡æ‹Ÿå‘é‡åŒ–æœåŠ¡æµ‹è¯•")
    logger.info("=" * 80)

    # åˆå§‹åŒ–æ•°æ®åº“
    await db_manager.init_database()
    logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    # åˆ›å»ºæ¨¡æ‹Ÿå‘é‡åŒ–æœåŠ¡
    vectorize_service = MockVectorizeService(max_workers=1)
    vectorize_service.start()
    logger.info("æ¨¡æ‹Ÿå‘é‡åŒ–æœåŠ¡å¯åŠ¨å®Œæˆ")

    return vectorize_service


def create_test_files():
    """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
    test_dir = Path(__file__).parent

    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£1
    doc1_path = test_dir / "mock_test_doc1.txt"
    with open(doc1_path, 'w', encoding='utf-8') as f:
        f.write("""
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯å‘é‡åŒ–åŠŸèƒ½ã€‚

ç¬¬ä¸€æ®µï¼šä»‹ç»äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µã€‚äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½è¡Œä¸ºçš„æœºå™¨å’Œç³»ç»Ÿã€‚

ç¬¬äºŒæ®µï¼šæœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ã€‚é€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œæ— éœ€æ˜ç¡®ç¼–ç¨‹å³å¯æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚

ç¬¬ä¸‰æ®µï¼šæ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å¤„ç†å¤æ‚çš„æ•°æ®æ¨¡å¼ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚

ç¬¬å››æ®µï¼šæœªæ¥äººå·¥æ™ºèƒ½å°†åœ¨åŒ»ç–—ã€æ•™è‚²ã€äº¤é€šã€é‡‘èç­‰å„ä¸ªé¢†åŸŸå‘æŒ¥æ›´é‡è¦çš„ä½œç”¨ï¼Œæ¨åŠ¨ç¤¾ä¼šå‘æ™ºèƒ½åŒ–æ–¹å‘å‘å±•ã€‚
""")

    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£2
    doc2_path = test_dir / "mock_test_doc2.txt"
    with open(doc2_path, 'w', encoding='utf-8') as f:
        f.write("""
äº‘è®¡ç®—æŠ€æœ¯æ¦‚è¿°æ–‡æ¡£

äº‘è®¡ç®—æ˜¯ä¸€ç§åŸºäºäº’è”ç½‘çš„è®¡ç®—æ–¹å¼ï¼Œé€šè¿‡ç½‘ç»œä»¥æŒ‰éœ€ã€æ˜“æ‰©å±•çš„æ–¹å¼è·å¾—æ‰€éœ€çš„è®¡ç®—èµ„æºã€‚

æœåŠ¡æ¨¡å‹ï¼š
- IaaSï¼ˆåŸºç¡€è®¾æ–½å³æœåŠ¡ï¼‰ï¼šæä¾›è™šæ‹ŸåŒ–çš„è®¡ç®—èµ„æº
- PaaSï¼ˆå¹³å°å³æœåŠ¡ï¼‰ï¼šæä¾›åº”ç”¨å¼€å‘å’Œéƒ¨ç½²å¹³å°  
- SaaSï¼ˆè½¯ä»¶å³æœåŠ¡ï¼‰ï¼šæä¾›å®Œæ•´çš„è½¯ä»¶åº”ç”¨

éƒ¨ç½²æ¨¡å¼ï¼š
- å…¬æœ‰äº‘ï¼šç”±ç¬¬ä¸‰æ–¹äº‘æœåŠ¡æä¾›å•†æ‹¥æœ‰å’Œè¿è¥
- ç§æœ‰äº‘ï¼šä¸“é—¨ä¸ºå•ä¸ªç»„ç»‡å»ºç«‹å’Œç»´æŠ¤
- æ··åˆäº‘ï¼šç»“åˆå…¬æœ‰äº‘å’Œç§æœ‰äº‘çš„ä¼˜åŠ¿

ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬æˆæœ¬æ•ˆç›Šã€å¼¹æ€§æ‰©å±•ã€é«˜å¯ç”¨æ€§å’Œå¿«é€Ÿéƒ¨ç½²ç­‰ç‰¹ç‚¹ã€‚
""")

    logger.info(f"åˆ›å»ºäº† 2 ä¸ªæµ‹è¯•æ–‡ä»¶")
    return [doc1_path, doc2_path]


async def test_mock_vectorization(vectorize_service, test_files):
    """æµ‹è¯•æ¨¡æ‹Ÿå‘é‡åŒ–åŠŸèƒ½"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•: æ¨¡æ‹Ÿå‘é‡åŒ–åŠŸèƒ½")
    logger.info("=" * 80)

    task_ids = []

    for test_file in test_files:
        # åˆ›å»ºä»»åŠ¡æ–‡ä»¶å¯¹è±¡
        task_file = TaskFile(
            file_id=str(uuid.uuid4()),
            original_name=test_file.name,
            file_name=test_file.name,
            file_path=str(test_file),
            file_type=test_file.suffix,
            file_size=test_file.stat().st_size
        )

        # æ·»åŠ ä»»åŠ¡
        task_id = vectorize_service.add_task(task_file)
        task_ids.append(task_id)
        logger.info(
            f"æ·»åŠ æ¨¡æ‹Ÿå‘é‡åŒ–ä»»åŠ¡: {task_id[:8]}..., æ–‡ä»¶: {task_file.original_name}")

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    results = []
    for task_id in task_ids:
        result = await wait_for_task_completion(vectorize_service, task_id, timeout=60)
        results.append(result)

    return results


async def wait_for_task_completion(vectorize_service, task_id, timeout=30):
    """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
    logger.info(f"ç­‰å¾…ä»»åŠ¡ {task_id[:8]}... å®Œæˆ")

    start_time = time.time()

    while time.time() - start_time < timeout:
        task_status = vectorize_service.get_task_status(task_id)

        if not task_status:
            logger.error(f"ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°")
            return None

        status = task_status['status']
        progress = task_status['progress']

        logger.info(f"ä»»åŠ¡è¿›åº¦: {progress:.1f}% - {status}")

        if status == 'completed':
            logger.info(f"âœ… ä»»åŠ¡ {task_id[:8]}... å®ŒæˆæˆåŠŸ!")
            return task_status
        elif status == 'failed':
            logger.error(
                f"âŒ ä»»åŠ¡ {task_id[:8]}... å¤±è´¥: {task_status.get('error_message', 'æœªçŸ¥é”™è¯¯')}")
            return task_status

        # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡æ–°æ£€æŸ¥
        await asyncio.sleep(1)

    logger.warning(f"â° ä»»åŠ¡ {task_id[:8]}... è¶…æ—¶")
    return None


async def test_database_results():
    """æµ‹è¯•æ•°æ®åº“ç»“æœ"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•: æ£€æŸ¥æ•°æ®åº“ç»“æœ")
    logger.info("=" * 80)

    # æ£€æŸ¥æ–‡ä»¶è®°å½•
    all_files = await db_manager.get_all_files()
    logger.info(f"ğŸ“ æ•°æ®åº“ä¸­å…±æœ‰ {len(all_files)} ä¸ªæ–‡ä»¶è®°å½•")

    vectorized_count = 0
    for file_info in all_files:
        status = "âœ… å·²å‘é‡åŒ–" if file_info['vectorized'] else "âŒ æœªå‘é‡åŒ–"
        logger.info(f"  ğŸ“„ {file_info['original_name']} - {status}")
        if file_info['vectorized']:
            vectorized_count += 1
            logger.info(f"     å‘é‡åŒ–æ—¶é—´: {file_info['vectorized_at']}")

    logger.info(f"ğŸ“Š å‘é‡åŒ–ç»Ÿè®¡: {vectorized_count}/{len(all_files)} ä¸ªæ–‡ä»¶å·²å‘é‡åŒ–")

    # æ£€æŸ¥æ–‡æ¡£å—
    all_chunks = await db_manager.get_all_document_chunks()
    logger.info(f"ğŸ§© æ•°æ®åº“ä¸­å…±æœ‰ {len(all_chunks)} ä¸ªæ–‡æ¡£å—")

    # æŒ‰æ–‡æ¡£ç»Ÿè®¡
    doc_chunks = {}
    for chunk in all_chunks:
        doc_id = chunk['document_id']
        if doc_id not in doc_chunks:
            doc_chunks[doc_id] = []
        doc_chunks[doc_id].append(chunk)

    for doc_id, chunks in doc_chunks.items():
        logger.info(f"  ğŸ“‘ æ–‡æ¡£ {doc_id}: {len(chunks)} ä¸ªæ–‡æœ¬å—")
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå—çš„å‘é‡ç»´åº¦
        if chunks:
            embedding = chunks[0]['embedding']
            logger.info(f"     å‘é‡ç»´åº¦: {len(embedding)}")


async def test_vectorized_status_api(vectorize_service):
    """æµ‹è¯•å‘é‡åŒ–çŠ¶æ€API"""
    logger.info("=" * 80)
    logger.info("æµ‹è¯•: å‘é‡åŒ–çŠ¶æ€API")
    logger.info("=" * 80)

    # è·å–æ‰€æœ‰æ–‡ä»¶
    all_files = await db_manager.get_all_files()

    for file_info in all_files:
        file_id = file_info['file_id']

        # ä½¿ç”¨å‘é‡åŒ–æœåŠ¡çš„APIè·å–çŠ¶æ€
        status = await vectorize_service.get_file_vectorized_status(file_id)

        if status:
            logger.info(f"ğŸ“„ {status['original_name']}")
            logger.info(
                f"   çŠ¶æ€: {'âœ… å·²å‘é‡åŒ–' if status['vectorized'] else 'âŒ æœªå‘é‡åŒ–'}")
            if status['vectorized_at']:
                logger.info(f"   æ—¶é—´: {status['vectorized_at']}")
        else:
            logger.warning(f"âŒ æ— æ³•è·å–æ–‡ä»¶ {file_id} çš„çŠ¶æ€")

    # è·å–æœªå‘é‡åŒ–æ–‡ä»¶
    unvectorized = await vectorize_service.get_unvectorized_files()
    logger.info(f"ğŸ“‹ æœªå‘é‡åŒ–æ–‡ä»¶: {len(unvectorized)} ä¸ª")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    try:
        # åˆå§‹åŒ–
        vectorize_service = await setup()

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_files = create_test_files()

        # æµ‹è¯•æ¨¡æ‹Ÿå‘é‡åŒ–
        await test_mock_vectorization(vectorize_service, test_files)

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(2)

        # æ£€æŸ¥æ•°æ®åº“ç»“æœ
        await test_database_results()

        # æµ‹è¯•çŠ¶æ€API
        await test_vectorized_status_api(vectorize_service)

        logger.info("=" * 80)
        logger.info("ğŸ‰ æ‰€æœ‰æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆ!")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())

    finally:
        # åœæ­¢å‘é‡åŒ–æœåŠ¡
        if 'vectorize_service' in locals():
            vectorize_service.stop()
            logger.info("å‘é‡åŒ–æœåŠ¡å·²åœæ­¢")


if __name__ == "__main__":
    # è®¾ç½®æ¨¡æ‹Ÿç¯å¢ƒå˜é‡ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if not os.getenv("OPENAI_API_KEY"):
        os.environ["OPENAI_API_KEY"] = "mock-key"
    if not os.getenv("OPENAI_URL"):
        os.environ["OPENAI_URL"] = "https://mock-api.example.com"
    if not os.getenv("MODEL_NAME"):
        os.environ["MODEL_NAME"] = "mock-model"

    logger.info("ğŸ§ª è¿è¡Œæ¨¡æ‹Ÿå‘é‡åŒ–æµ‹è¯•")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
